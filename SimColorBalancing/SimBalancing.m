function [renderImage] = SimBalancing(inputImage,S_acquireSpd,spd_acquire,S_renderSpd,spd_render,...		S_renderT,T_render,S_surfaceB,B_surface)% [renderImage] = SimBalancing(inputImage,S_acquire,spd_acquire,S_renderSpd,spd_render,...%		S_renderT,T_render,S_surfaceB,B_surface)%% Balances camera data acquired under one illuminant% to data seen under another illuminant by a specified% sensor set.%% We assume that the input to this routine has been linearized, so that% the pixel data we get here could actually be predicted from physical% measurements of light and the camera spectral sensitivities.  Any % non-linearities should be processed out before we get here.%% Spectral power distributions should be expressed in Watts/sr-m2, and% T_render should be energy sensitivities.  After this routine has acted% the image will be with respect to T_render and thus expressed with% respect to energy sensitivities, no matter how it came in.%% 07/15/98   pxl  Wrote it.% 08/13/98   pxl  Renamed it from KnownIlluminant.% 10/30/98   dhb  Added comments.% 11/02/98   pxl  Added more parameters ...% 11/09/98   dhb  Changed variable names, allowed input camera structure.%            dhb  Modify image to contain camera structure, itself modified%				  to reflect rendering sensitivities.%            dhb  Comment out scale factor.% 11/26/98   pxl  Checked for quantaa spectra, added factors in this case.% 12/7/98    dhb  Cosmetic editing.% 12/8/98    dhb  Spline all spectral functions to camera sensor resolution.% 12/17/98   dhb  Clean up debugging code.% 12/18/98   dhb  Do tranform through subroutine.%            dhb  Rendered type doesn't change, we're still in a sensor space here.% 12/29/98   dhb  Handle quantal weights through subroutine and change writing%                 of camera sensitivities on output to match.% Read the image and camera descriptions.if (isstruct(inputImage))  renderImage = inputImage;else  renderImage = SimReadImage(inputImage); endif (~isstruct(renderImage.cameraFile))	camera = SimReadCamera(renderImage.cameraFile);else	camera = renderImage.cameraFile;end% Check that its not mosaicedif (inputImage.mosaiced == 1)	error('Cannot balance mosaiced image');end% Get effective sensors, ready for use with Watts/sr-m2.T_in = SimAdjustSensors(inputImage,camera);% Load surface data and human sensors.  Take defaults if% data are not passed.if ((nargin  < 9) | (isempty(B_surface)))  load B_nickerson;  B_surface = B_nickerson(:,1:camera.numberSensors);	S_surfaceB = S_nickerson;	clear B_nickerson S_nickerson;else  B_surface = B_surface(:,1:camera.numberSensors);endif ((nargin<7) | (isempty(T_render)))   load T_xyz1931;  T_render = 683*T_xyz1931;  S_renderT = S_xyz1931;  clear T_xyz1931 S_xyz1931end% Spline stuff down to common wavelenth samplingS_use = [camera.wavelengthSampling.start camera.wavelengthSampling.step camera.wavelengthSampling.numberSamples];B_surface = SplineSrf(S_surfaceB,B_surface,S_use);T_render = SplineCmf(S_renderT,T_render,S_use);spd_acquire = SplineSpd(S_acquireSpd,spd_acquire,S_use);spd_render = SplineSpd(S_renderSpd,spd_render,S_use);% Compute correction matrix.M_acquireToSur = inv(T_in*diag(spd_acquire)*B_surface);M_surToRender = T_render*diag(spd_render)*B_surface;% Actual balancing from acquire to render device/illuminant space.% Need to reshape data to apply correction.renderImage.colorMatrix = M_surToRender*M_acquireToSur;renderImage.images = SimApplyColorTransform(M_surToRender*M_acquireToSur,renderImage.images);renderImage.bits = Inf;% Update renderImage camera to reflect rendered sensitivities.% Since we are rendering with color matching functions expressed% in energy units, we override units, exposureTime, and fStop so% that everything will stay consistent further down the pike.camera.spectralSensitivity = T_render;camera.unit = 'Watts';camera.calExposureTime = renderImage.exposureTime;camera.calFStop = renderImage.fStop;renderImage.cameraFile = camera;